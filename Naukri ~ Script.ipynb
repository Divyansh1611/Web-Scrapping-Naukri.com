{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "fb5f4630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as req\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import * \n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "ce071828",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--start-maximized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "525d1be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_drive_path = r\"C:\\Users\\chaud\\Desktop\\GoogleChromeDriver\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "9cbd887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_url = \"https://www.naukri.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "25e49f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "fbca3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(web_drive_path, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "13f026dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(website_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "630448fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 7)# wait till 7 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "68c551f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchbox= wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"root\"]/div[7]/div/div/div[1]/div/div/div/div[1]/div/input')))\n",
    "searchbox.send_keys(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "db0f43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"root\"]/div[7]/div/div/div[6]')))\n",
    "submit.click()\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "38ed78d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "freshness_Job = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"search-result-container\"]/div[1]/div[1]/div/div/div[2]/div[14]/div[2]/div')))\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", freshness_Job)\n",
    "freshness_Job.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "2a220568",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_last_7_days = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"search-result-container\"]/div[1]/div[1]/div/div/div[2]/div[14]/div[2]/div/div/ul/li[3]')))\n",
    "select_last_7_days.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "ed6f85cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "0e9b39ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting job data for listing 16.\n",
      "Error extracting job data for listing 2.\n",
      "Error extracting job data for listing 3.\n",
      "Error extracting job data for listing 15.\n",
      "Error extracting job data for listing 17.\n",
      "Error extracting job data for listing 18.\n",
      "Error extracting job data for listing 19.\n",
      "Error extracting job data for listing 4.\n",
      "Error extracting job data for listing 9.\n",
      "Error extracting job data for listing 10.\n",
      "Error extracting job data for listing 19.\n",
      "Error extracting job data for listing 9.\n",
      "Error extracting job data for listing 10.\n",
      "Error extracting job data for listing 4.\n",
      "Error extracting job data for listing 6.\n",
      "Error extracting job data for listing 11.\n",
      "Error extracting job data for listing 3.\n",
      "Error extracting job data for listing 5.\n",
      "Error extracting job data for listing 12.\n",
      "Error extracting job data for listing 13.\n",
      "Error extracting job data for listing 17.\n",
      "Error extracting job data for listing 4.\n",
      "Error extracting job data for listing 18.\n",
      "Error extracting job data for listing 8.\n",
      "Error extracting job data for listing 3.\n",
      "Error extracting job data for listing 14.\n",
      "Error extracting job data for listing 3.\n",
      "Error extracting job data for listing 11.\n",
      "Error extracting job data for listing 16.\n",
      "Error extracting job data for listing 19.\n",
      "Error extracting job data for listing 14.\n",
      "Error extracting job data for listing 9.\n",
      "Error extracting job data for listing 14.\n",
      "Error extracting job data for listing 13.\n",
      "Error extracting job data for listing 15.\n",
      "Error extracting job data for listing 3.\n",
      "Error extracting job data for listing 18.\n",
      "Error extracting job data for listing 11.\n",
      "Error extracting job data for listing 14.\n",
      "Error extracting job data for listing 14.\n",
      "Error extracting job data for listing 7.\n",
      "Error extracting job data for listing 0.\n",
      "Error extracting job data for listing 0.\n",
      "Error extracting job data for listing 11.\n",
      "Error extracting job data for listing 13.\n",
      "Error extracting job data for listing 9.\n",
      "Error extracting job data for listing 8.\n",
      "Error extracting job data for listing 14.\n",
      "Error extracting job data for listing 2.\n",
      "Error extracting job data for listing 7.\n",
      "Error extracting job data for listing 3.\n",
      "Error extracting job data for listing 8.\n",
      "Error extracting job data for listing 8.\n",
      "Error extracting job data for listing 11.\n",
      "Error extracting job data for listing 6.\n",
      "Error extracting job data for listing 11.\n",
      "Error extracting job data for listing 18.\n",
      "Error extracting job data for listing 10.\n",
      "Error extracting job data for listing 11.\n",
      "Error extracting job data for listing 0.\n",
      "Error extracting job data for listing 18.\n",
      "Error extracting job data for listing 5.\n",
      "Error extracting job data for listing 8.\n",
      "Error extracting job data for listing 6.\n",
      "Error extracting job data for listing 9.\n",
      "Error extracting job data for listing 19.\n",
      "Error extracting job data for listing 2.\n",
      "Error extracting job data for listing 11.\n",
      "Error extracting job data for listing 15.\n",
      "Error extracting job data for listing 18.\n",
      "Error extracting job data for listing 18.\n",
      "Error extracting job data for listing 15.\n",
      "Error extracting job data for listing 8.\n",
      "Error extracting job data for listing 18.\n",
      "Error extracting job data for listing 0.\n",
      "Error extracting job data for listing 18.\n",
      "Error extracting job data for listing 0.\n",
      "Error extracting job data for listing 2.\n",
      "Error extracting job data for listing 5.\n",
      "Error extracting job data for listing 5.\n",
      "Error extracting job data for listing 16.\n",
      "Error extracting job data for listing 12.\n",
      "Error extracting job data for listing 5.\n",
      "Error extracting job data for listing 17.\n",
      "Error extracting job data for listing 8.\n",
      "Error extracting job data for listing 15.\n",
      "Error extracting job data for listing 19.\n",
      "Error extracting job data for listing 0.\n",
      "Error extracting job data for listing 2.\n",
      "Error extracting job data for listing 19.\n",
      "Error extracting job data for listing 6.\n",
      "Error extracting job data for listing 7.\n",
      "Error extracting job data for listing 18.\n",
      "Error extracting job data for listing 3.\n",
      "Error extracting job data for listing 0.\n",
      "Error extracting job data for listing 1.\n",
      "Error extracting job data for listing 13.\n",
      "Error extracting job data for listing 18.\n",
      "Error extracting job data for listing 0.\n",
      "Error extracting job data for listing 10.\n",
      "Error extracting job data for listing 3.\n",
      "Error extracting job data for listing 4.\n",
      "Error extracting job data for listing 18.\n",
      "Error extracting job data for listing 19.\n",
      "Error extracting job data for listing 0.\n",
      "Error extracting job data for listing 5.\n",
      "Error extracting job data for listing 14.\n",
      "Error extracting job data for listing 2.\n",
      "Error extracting job data for listing 8.\n",
      "Error extracting job data for listing 1.\n",
      "Error extracting job data for listing 13.\n",
      "Error extracting job data for listing 14.\n",
      "Error extracting job data for listing 15.\n",
      "Error extracting job data for listing 16.\n",
      "Error extracting job data for listing 17.\n",
      "Error extracting job data for listing 18.\n",
      "Error extracting job data for listing 19.\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[668], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 3\u001b[0m     feed_list \u001b[38;5;241m=\u001b[39m WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(EC\u001b[38;5;241m.\u001b[39mpresence_of_all_elements_located((By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrp-jobtuple-wrapper\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m      4\u001b[0m     main_page_script \u001b[38;5;241m=\u001b[39m WebDriverWait(driver, \u001b[38;5;241m7\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(EC\u001b[38;5;241m.\u001b[39mpresence_of_element_located((By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@id=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch-result-container\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]/div[1]/script[2]\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      5\u001b[0m     main_page_script_pointers \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(main_page_script\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minnerHTML\u001b[39m\u001b[38;5;124m'\u001b[39m))[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitemListElement\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:80\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    \n",
    "    feed_list = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"srp-jobtuple-wrapper\")))\n",
    "    main_page_script = WebDriverWait(driver, 7).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"search-result-container\"]/div[1]/script[2]')))\n",
    "    main_page_script_pointers = json.loads(main_page_script.get_attribute('innerHTML'))['itemListElement']\n",
    "    \n",
    "    job_days = WebDriverWait(driver, 7).until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'job-post-day')))\n",
    "    job_days_text = [elem.text for elem in job_days]\n",
    "    \n",
    "    for i in range(len(feed_list)):\n",
    "        if \"Today\" in job_days_text[i] or \"Just Now\" in job_days_text[i] or \"Few Hours Ago\" in job_days_text[i] or \"Few Minutes Ago\" in job_days_text[i]:\n",
    "            num_days = 0  # Consider these as 0 days old\n",
    "        else:\n",
    "            # Try to extract the number of days from the string\n",
    "            try:\n",
    "                num_days = int(job_days_text[i].split()[0])  # Extract the number from the text\n",
    "            except ValueError:\n",
    "                # In case there's any other unexpected format, set num_days to 0 or skip\n",
    "                continue\n",
    "        \n",
    "        if num_days > 7:\n",
    "            break\n",
    "                \n",
    "        else:\n",
    "            # Store the current window handle\n",
    "            main_window = driver.current_window_handle\n",
    "            try:\n",
    "                # Click on the job listing to open in a new tab\n",
    "                feed_list[i].click()\n",
    "                time.sleep(3)\n",
    "\n",
    "                # Get all the window handles\n",
    "                windows = driver.window_handles\n",
    "                # Switch to the new tab (the last opened window)\n",
    "                driver.switch_to.window(windows[-1])\n",
    "\n",
    "                try:\n",
    "                    # Extract the job details from the script element\n",
    "                    job_link = WebDriverWait(driver, 7).until(EC.presence_of_all_elements_located((By.XPATH, '//*[@id=\"root\"]/div/script[1]')))\n",
    "                    job_data_json = json.loads(job_link[0].get_attribute('innerHTML'))\n",
    "\n",
    "                    # Initialize empty dictionary to store job data\n",
    "                    job_data = {}\n",
    "\n",
    "                    # Keys to extract from JSON obje\n",
    "\n",
    "                    # Append the complete job_data dictionary to temp_data list\n",
    "                    job_data['URL'] = main_page_script_pointers[i].get('url', 'None')  # Fallback URL\n",
    "                    job_data['name'] = main_page_script_pointers[i].get('name', 'Unknown Job')\n",
    "                    \n",
    "                    temp_data.append(job_data)\n",
    "\n",
    "                except TimeoutException:\n",
    "                    print(f\"Error extracting job data for listing {i}.\")\n",
    "\n",
    "                # Close the new tab\n",
    "                driver.close()\n",
    "                # Switch back to the main window\n",
    "                driver.switch_to.window(main_window)\n",
    "\n",
    "            except Exception as e:\n",
    "                # Handle cases where the job feed click or tab handling fails\n",
    "                print(f\"Error processing job listing {i}: {e}\")\n",
    "                continue  # Continue to the next listing\n",
    "\n",
    "    next_button = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"lastCompMark\"]/a[2]')))\n",
    "    if next_button.get_attribute('disabled'):\n",
    "        print(\"Reached the last page.\")\n",
    "        break\n",
    "    next_button.click()\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "c2b99044",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_Name = f\"{keyword}-Naurki.csv\"\n",
    "pd.DataFrame(temp_data).to_csv(file_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301377b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56658ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef6b158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac5e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383fbbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
